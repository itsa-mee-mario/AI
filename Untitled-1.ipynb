{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([[1,2,3],[3,4,5]]) # 2x3\n",
    "b = torch.tensor([[1,2,3],[3,4,5]]).T # 3x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), torch.Size([3, 2]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 4, 5]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[1:,] # second row and all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4, 5])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[:,1] # all rows and second column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), torch.Size([2, 3, 1]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape, a.unsqueeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "A = np.array([0, 1, 2])\n",
    "\n",
    "B = np.array([[ 0,  1,  2,  3],\n",
    "              [ 4,  5,  6,  7],\n",
    "              [ 8,  9, 10, 11]])\n",
    "              \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3,), (3, 4))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape, B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True],\n",
       "        [True],\n",
       "        [True]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(A[:, np.newaxis]) == torch.tensor(A).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [16, 18, 20, 22]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.einsum(\"i, ij -> ij\", A, B) \n",
    "# this multiplies the elements in A with corresponding rows in B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20, 23, 26, 29])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.einsum(\"i, ij -> j\", A, B) \n",
    "# this multiplies the elements in A with corresponding rows in B and then sums them column wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 22, 76])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.einsum(\"i, ij -> i\", A, B) \n",
    "# this multiplies the elements in A with corresponding rows in B and then sums them row wise. then transposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mSignature:\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moperands\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSource:\u001b[0m   \n",
      "\u001b[0;34m@\u001b[0m\u001b[0marray_function_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_einsum_dispatcher\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'numpy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;32mdef\u001b[0m \u001b[0meinsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moperands\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;34m\"\"\"\u001b[0m\n",
      "\u001b[0;34m    einsum(subscripts, *operands, out=None, dtype=None, order='K',\u001b[0m\n",
      "\u001b[0;34m           casting='safe', optimize=False)\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Evaluates the Einstein summation convention on the operands.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Using the Einstein summation convention, many common multi-dimensional,\u001b[0m\n",
      "\u001b[0;34m    linear algebraic array operations can be represented in a simple fashion.\u001b[0m\n",
      "\u001b[0;34m    In *implicit* mode `einsum` computes these values.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    In *explicit* mode, `einsum` provides further flexibility to compute\u001b[0m\n",
      "\u001b[0;34m    other array operations that might not be considered classical Einstein\u001b[0m\n",
      "\u001b[0;34m    summation operations, by disabling, or forcing summation over specified\u001b[0m\n",
      "\u001b[0;34m    subscript labels.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    See the notes and examples for clarification.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Parameters\u001b[0m\n",
      "\u001b[0;34m    ----------\u001b[0m\n",
      "\u001b[0;34m    subscripts : str\u001b[0m\n",
      "\u001b[0;34m        Specifies the subscripts for summation as comma separated list of\u001b[0m\n",
      "\u001b[0;34m        subscript labels. An implicit (classical Einstein summation)\u001b[0m\n",
      "\u001b[0;34m        calculation is performed unless the explicit indicator '->' is\u001b[0m\n",
      "\u001b[0;34m        included as well as subscript labels of the precise output form.\u001b[0m\n",
      "\u001b[0;34m    operands : list of array_like\u001b[0m\n",
      "\u001b[0;34m        These are the arrays for the operation.\u001b[0m\n",
      "\u001b[0;34m    out : ndarray, optional\u001b[0m\n",
      "\u001b[0;34m        If provided, the calculation is done into this array.\u001b[0m\n",
      "\u001b[0;34m    dtype : {data-type, None}, optional\u001b[0m\n",
      "\u001b[0;34m        If provided, forces the calculation to use the data type specified.\u001b[0m\n",
      "\u001b[0;34m        Note that you may have to also give a more liberal `casting`\u001b[0m\n",
      "\u001b[0;34m        parameter to allow the conversions. Default is None.\u001b[0m\n",
      "\u001b[0;34m    order : {'C', 'F', 'A', 'K'}, optional\u001b[0m\n",
      "\u001b[0;34m        Controls the memory layout of the output. 'C' means it should\u001b[0m\n",
      "\u001b[0;34m        be C contiguous. 'F' means it should be Fortran contiguous,\u001b[0m\n",
      "\u001b[0;34m        'A' means it should be 'F' if the inputs are all 'F', 'C' otherwise.\u001b[0m\n",
      "\u001b[0;34m        'K' means it should be as close to the layout as the inputs as\u001b[0m\n",
      "\u001b[0;34m        is possible, including arbitrarily permuted axes.\u001b[0m\n",
      "\u001b[0;34m        Default is 'K'.\u001b[0m\n",
      "\u001b[0;34m    casting : {'no', 'equiv', 'safe', 'same_kind', 'unsafe'}, optional\u001b[0m\n",
      "\u001b[0;34m        Controls what kind of data casting may occur.  Setting this to\u001b[0m\n",
      "\u001b[0;34m        'unsafe' is not recommended, as it can adversely affect accumulations.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m          * 'no' means the data types should not be cast at all.\u001b[0m\n",
      "\u001b[0;34m          * 'equiv' means only byte-order changes are allowed.\u001b[0m\n",
      "\u001b[0;34m          * 'safe' means only casts which can preserve values are allowed.\u001b[0m\n",
      "\u001b[0;34m          * 'same_kind' means only safe casts or casts within a kind,\u001b[0m\n",
      "\u001b[0;34m            like float64 to float32, are allowed.\u001b[0m\n",
      "\u001b[0;34m          * 'unsafe' means any data conversions may be done.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m        Default is 'safe'.\u001b[0m\n",
      "\u001b[0;34m    optimize : {False, True, 'greedy', 'optimal'}, optional\u001b[0m\n",
      "\u001b[0;34m        Controls if intermediate optimization should occur. No optimization\u001b[0m\n",
      "\u001b[0;34m        will occur if False and True will default to the 'greedy' algorithm.\u001b[0m\n",
      "\u001b[0;34m        Also accepts an explicit contraction list from the ``np.einsum_path``\u001b[0m\n",
      "\u001b[0;34m        function. See ``np.einsum_path`` for more details. Defaults to False.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Returns\u001b[0m\n",
      "\u001b[0;34m    -------\u001b[0m\n",
      "\u001b[0;34m    output : ndarray\u001b[0m\n",
      "\u001b[0;34m        The calculation based on the Einstein summation convention.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    See Also\u001b[0m\n",
      "\u001b[0;34m    --------\u001b[0m\n",
      "\u001b[0;34m    einsum_path, dot, inner, outer, tensordot, linalg.multi_dot\u001b[0m\n",
      "\u001b[0;34m    einops :\u001b[0m\n",
      "\u001b[0;34m        similar verbose interface is provided by\u001b[0m\n",
      "\u001b[0;34m        `einops <https://github.com/arogozhnikov/einops>`_ package to cover\u001b[0m\n",
      "\u001b[0;34m        additional operations: transpose, reshape/flatten, repeat/tile,\u001b[0m\n",
      "\u001b[0;34m        squeeze/unsqueeze and reductions.\u001b[0m\n",
      "\u001b[0;34m    opt_einsum :\u001b[0m\n",
      "\u001b[0;34m        `opt_einsum <https://optimized-einsum.readthedocs.io/en/stable/>`_\u001b[0m\n",
      "\u001b[0;34m        optimizes contraction order for einsum-like expressions\u001b[0m\n",
      "\u001b[0;34m        in backend-agnostic manner.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Notes\u001b[0m\n",
      "\u001b[0;34m    -----\u001b[0m\n",
      "\u001b[0;34m    .. versionadded:: 1.6.0\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    The Einstein summation convention can be used to compute\u001b[0m\n",
      "\u001b[0;34m    many multi-dimensional, linear algebraic array operations. `einsum`\u001b[0m\n",
      "\u001b[0;34m    provides a succinct way of representing these.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    A non-exhaustive list of these operations,\u001b[0m\n",
      "\u001b[0;34m    which can be computed by `einsum`, is shown below along with examples:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    * Trace of an array, :py:func:`numpy.trace`.\u001b[0m\n",
      "\u001b[0;34m    * Return a diagonal, :py:func:`numpy.diag`.\u001b[0m\n",
      "\u001b[0;34m    * Array axis summations, :py:func:`numpy.sum`.\u001b[0m\n",
      "\u001b[0;34m    * Transpositions and permutations, :py:func:`numpy.transpose`.\u001b[0m\n",
      "\u001b[0;34m    * Matrix multiplication and dot product, :py:func:`numpy.matmul` :py:func:`numpy.dot`.\u001b[0m\n",
      "\u001b[0;34m    * Vector inner and outer products, :py:func:`numpy.inner` :py:func:`numpy.outer`.\u001b[0m\n",
      "\u001b[0;34m    * Broadcasting, element-wise and scalar multiplication, :py:func:`numpy.multiply`.\u001b[0m\n",
      "\u001b[0;34m    * Tensor contractions, :py:func:`numpy.tensordot`.\u001b[0m\n",
      "\u001b[0;34m    * Chained array operations, in efficient calculation order, :py:func:`numpy.einsum_path`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    The subscripts string is a comma-separated list of subscript labels,\u001b[0m\n",
      "\u001b[0;34m    where each label refers to a dimension of the corresponding operand.\u001b[0m\n",
      "\u001b[0;34m    Whenever a label is repeated it is summed, so ``np.einsum('i,i', a, b)``\u001b[0m\n",
      "\u001b[0;34m    is equivalent to :py:func:`np.inner(a,b) <numpy.inner>`. If a label\u001b[0m\n",
      "\u001b[0;34m    appears only once, it is not summed, so ``np.einsum('i', a)`` produces a\u001b[0m\n",
      "\u001b[0;34m    view of ``a`` with no changes. A further example ``np.einsum('ij,jk', a, b)``\u001b[0m\n",
      "\u001b[0;34m    describes traditional matrix multiplication and is equivalent to\u001b[0m\n",
      "\u001b[0;34m    :py:func:`np.matmul(a,b) <numpy.matmul>`. Repeated subscript labels in one\u001b[0m\n",
      "\u001b[0;34m    operand take the diagonal. For example, ``np.einsum('ii', a)`` is equivalent\u001b[0m\n",
      "\u001b[0;34m    to :py:func:`np.trace(a) <numpy.trace>`.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    In *implicit mode*, the chosen subscripts are important\u001b[0m\n",
      "\u001b[0;34m    since the axes of the output are reordered alphabetically.  This\u001b[0m\n",
      "\u001b[0;34m    means that ``np.einsum('ij', a)`` doesn't affect a 2D array, while\u001b[0m\n",
      "\u001b[0;34m    ``np.einsum('ji', a)`` takes its transpose. Additionally,\u001b[0m\n",
      "\u001b[0;34m    ``np.einsum('ij,jk', a, b)`` returns a matrix multiplication, while,\u001b[0m\n",
      "\u001b[0;34m    ``np.einsum('ij,jh', a, b)`` returns the transpose of the\u001b[0m\n",
      "\u001b[0;34m    multiplication since subscript 'h' precedes subscript 'i'.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    In *explicit mode* the output can be directly controlled by\u001b[0m\n",
      "\u001b[0;34m    specifying output subscript labels.  This requires the\u001b[0m\n",
      "\u001b[0;34m    identifier '->' as well as the list of output subscript labels.\u001b[0m\n",
      "\u001b[0;34m    This feature increases the flexibility of the function since\u001b[0m\n",
      "\u001b[0;34m    summing can be disabled or forced when required. The call\u001b[0m\n",
      "\u001b[0;34m    ``np.einsum('i->', a)`` is like :py:func:`np.sum(a, axis=-1) <numpy.sum>`,\u001b[0m\n",
      "\u001b[0;34m    and ``np.einsum('ii->i', a)`` is like :py:func:`np.diag(a) <numpy.diag>`.\u001b[0m\n",
      "\u001b[0;34m    The difference is that `einsum` does not allow broadcasting by default.\u001b[0m\n",
      "\u001b[0;34m    Additionally ``np.einsum('ij,jh->ih', a, b)`` directly specifies the\u001b[0m\n",
      "\u001b[0;34m    order of the output subscript labels and therefore returns matrix\u001b[0m\n",
      "\u001b[0;34m    multiplication, unlike the example above in implicit mode.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    To enable and control broadcasting, use an ellipsis.  Default\u001b[0m\n",
      "\u001b[0;34m    NumPy-style broadcasting is done by adding an ellipsis\u001b[0m\n",
      "\u001b[0;34m    to the left of each term, like ``np.einsum('...ii->...i', a)``.\u001b[0m\n",
      "\u001b[0;34m    To take the trace along the first and last axes,\u001b[0m\n",
      "\u001b[0;34m    you can do ``np.einsum('i...i', a)``, or to do a matrix-matrix\u001b[0m\n",
      "\u001b[0;34m    product with the left-most indices instead of rightmost, one can do\u001b[0m\n",
      "\u001b[0;34m    ``np.einsum('ij...,jk...->ik...', a, b)``.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    When there is only one operand, no axes are summed, and no output\u001b[0m\n",
      "\u001b[0;34m    parameter is provided, a view into the operand is returned instead\u001b[0m\n",
      "\u001b[0;34m    of a new array.  Thus, taking the diagonal as ``np.einsum('ii->i', a)``\u001b[0m\n",
      "\u001b[0;34m    produces a view (changed in version 1.10.0).\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    `einsum` also provides an alternative way to provide the subscripts\u001b[0m\n",
      "\u001b[0;34m    and operands as ``einsum(op0, sublist0, op1, sublist1, ..., [sublistout])``.\u001b[0m\n",
      "\u001b[0;34m    If the output shape is not provided in this format `einsum` will be\u001b[0m\n",
      "\u001b[0;34m    calculated in implicit mode, otherwise it will be performed explicitly.\u001b[0m\n",
      "\u001b[0;34m    The examples below have corresponding `einsum` calls with the two\u001b[0m\n",
      "\u001b[0;34m    parameter methods.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    .. versionadded:: 1.10.0\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Views returned from einsum are now writeable whenever the input array\u001b[0m\n",
      "\u001b[0;34m    is writeable. For example, ``np.einsum('ijk...->kji...', a)`` will now\u001b[0m\n",
      "\u001b[0;34m    have the same effect as :py:func:`np.swapaxes(a, 0, 2) <numpy.swapaxes>`\u001b[0m\n",
      "\u001b[0;34m    and ``np.einsum('ii->i', a)`` will return a writeable view of the diagonal\u001b[0m\n",
      "\u001b[0;34m    of a 2D array.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    .. versionadded:: 1.12.0\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Added the ``optimize`` argument which will optimize the contraction order\u001b[0m\n",
      "\u001b[0;34m    of an einsum expression. For a contraction with three or more operands this\u001b[0m\n",
      "\u001b[0;34m    can greatly increase the computational efficiency at the cost of a larger\u001b[0m\n",
      "\u001b[0;34m    memory footprint during computation.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Typically a 'greedy' algorithm is applied which empirical tests have shown\u001b[0m\n",
      "\u001b[0;34m    returns the optimal path in the majority of cases. In some cases 'optimal'\u001b[0m\n",
      "\u001b[0;34m    will return the superlative path through a more expensive, exhaustive search.\u001b[0m\n",
      "\u001b[0;34m    For iterative calculations it may be advisable to calculate the optimal path\u001b[0m\n",
      "\u001b[0;34m    once and reuse that path by supplying it as an argument. An example is given\u001b[0m\n",
      "\u001b[0;34m    below.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    See :py:func:`numpy.einsum_path` for more details.\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Examples\u001b[0m\n",
      "\u001b[0;34m    --------\u001b[0m\n",
      "\u001b[0;34m    >>> a = np.arange(25).reshape(5,5)\u001b[0m\n",
      "\u001b[0;34m    >>> b = np.arange(5)\u001b[0m\n",
      "\u001b[0;34m    >>> c = np.arange(6).reshape(2,3)\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Trace of a matrix:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> np.einsum('ii', a)\u001b[0m\n",
      "\u001b[0;34m    60\u001b[0m\n",
      "\u001b[0;34m    >>> np.einsum(a, [0,0])\u001b[0m\n",
      "\u001b[0;34m    60\u001b[0m\n",
      "\u001b[0;34m    >>> np.trace(a)\u001b[0m\n",
      "\u001b[0;34m    60\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Extract the diagonal (requires explicit form):\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> np.einsum('ii->i', a)\u001b[0m\n",
      "\u001b[0;34m    array([ 0,  6, 12, 18, 24])\u001b[0m\n",
      "\u001b[0;34m    >>> np.einsum(a, [0,0], [0])\u001b[0m\n",
      "\u001b[0;34m    array([ 0,  6, 12, 18, 24])\u001b[0m\n",
      "\u001b[0;34m    >>> np.diag(a)\u001b[0m\n",
      "\u001b[0;34m    array([ 0,  6, 12, 18, 24])\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Sum over an axis (requires explicit form):\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> np.einsum('ij->i', a)\u001b[0m\n",
      "\u001b[0;34m    array([ 10,  35,  60,  85, 110])\u001b[0m\n",
      "\u001b[0;34m    >>> np.einsum(a, [0,1], [0])\u001b[0m\n",
      "\u001b[0;34m    array([ 10,  35,  60,  85, 110])\u001b[0m\n",
      "\u001b[0;34m    >>> np.sum(a, axis=1)\u001b[0m\n",
      "\u001b[0;34m    array([ 10,  35,  60,  85, 110])\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    For higher dimensional arrays summing a single axis can be done with ellipsis:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> np.einsum('...j->...', a)\u001b[0m\n",
      "\u001b[0;34m    array([ 10,  35,  60,  85, 110])\u001b[0m\n",
      "\u001b[0;34m    >>> np.einsum(a, [Ellipsis,1], [Ellipsis])\u001b[0m\n",
      "\u001b[0;34m    array([ 10,  35,  60,  85, 110])\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Compute a matrix transpose, or reorder any number of axes:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> np.einsum('ji', c)\u001b[0m\n",
      "\u001b[0;34m    array([[0, 3],\u001b[0m\n",
      "\u001b[0;34m           [1, 4],\u001b[0m\n",
      "\u001b[0;34m           [2, 5]])\u001b[0m\n",
      "\u001b[0;34m    >>> np.einsum('ij->ji', c)\u001b[0m\n",
      "\u001b[0;34m    array([[0, 3],\u001b[0m\n",
      "\u001b[0;34m           [1, 4],\u001b[0m\n",
      "\u001b[0;34m           [2, 5]])\u001b[0m\n",
      "\u001b[0;34m    >>> np.einsum(c, [1,0])\u001b[0m\n",
      "\u001b[0;34m    array([[0, 3],\u001b[0m\n",
      "\u001b[0;34m           [1, 4],\u001b[0m\n",
      "\u001b[0;34m           [2, 5]])\u001b[0m\n",
      "\u001b[0;34m    >>> np.transpose(c)\u001b[0m\n",
      "\u001b[0;34m    array([[0, 3],\u001b[0m\n",
      "\u001b[0;34m           [1, 4],\u001b[0m\n",
      "\u001b[0;34m           [2, 5]])\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Vector inner products:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> np.einsum('i,i', b, b)\u001b[0m\n",
      "\u001b[0;34m    30\u001b[0m\n",
      "\u001b[0;34m    >>> np.einsum(b, [0], b, [0])\u001b[0m\n",
      "\u001b[0;34m    30\u001b[0m\n",
      "\u001b[0;34m    >>> np.inner(b,b)\u001b[0m\n",
      "\u001b[0;34m    30\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Matrix vector multiplication:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> np.einsum('ij,j', a, b)\u001b[0m\n",
      "\u001b[0;34m    array([ 30,  80, 130, 180, 230])\u001b[0m\n",
      "\u001b[0;34m    >>> np.einsum(a, [0,1], b, [1])\u001b[0m\n",
      "\u001b[0;34m    array([ 30,  80, 130, 180, 230])\u001b[0m\n",
      "\u001b[0;34m    >>> np.dot(a, b)\u001b[0m\n",
      "\u001b[0;34m    array([ 30,  80, 130, 180, 230])\u001b[0m\n",
      "\u001b[0;34m    >>> np.einsum('...j,j', a, b)\u001b[0m\n",
      "\u001b[0;34m    array([ 30,  80, 130, 180, 230])\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Broadcasting and scalar multiplication:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> np.einsum('..., ...', 3, c)\u001b[0m\n",
      "\u001b[0;34m    array([[ 0,  3,  6],\u001b[0m\n",
      "\u001b[0;34m           [ 9, 12, 15]])\u001b[0m\n",
      "\u001b[0;34m    >>> np.einsum(',ij', 3, c)\u001b[0m\n",
      "\u001b[0;34m    array([[ 0,  3,  6],\u001b[0m\n",
      "\u001b[0;34m           [ 9, 12, 15]])\u001b[0m\n",
      "\u001b[0;34m    >>> np.einsum(3, [Ellipsis], c, [Ellipsis])\u001b[0m\n",
      "\u001b[0;34m    array([[ 0,  3,  6],\u001b[0m\n",
      "\u001b[0;34m           [ 9, 12, 15]])\u001b[0m\n",
      "\u001b[0;34m    >>> np.multiply(3, c)\u001b[0m\n",
      "\u001b[0;34m    array([[ 0,  3,  6],\u001b[0m\n",
      "\u001b[0;34m           [ 9, 12, 15]])\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Vector outer product:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> np.einsum('i,j', np.arange(2)+1, b)\u001b[0m\n",
      "\u001b[0;34m    array([[0, 1, 2, 3, 4],\u001b[0m\n",
      "\u001b[0;34m           [0, 2, 4, 6, 8]])\u001b[0m\n",
      "\u001b[0;34m    >>> np.einsum(np.arange(2)+1, [0], b, [1])\u001b[0m\n",
      "\u001b[0;34m    array([[0, 1, 2, 3, 4],\u001b[0m\n",
      "\u001b[0;34m           [0, 2, 4, 6, 8]])\u001b[0m\n",
      "\u001b[0;34m    >>> np.outer(np.arange(2)+1, b)\u001b[0m\n",
      "\u001b[0;34m    array([[0, 1, 2, 3, 4],\u001b[0m\n",
      "\u001b[0;34m           [0, 2, 4, 6, 8]])\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Tensor contraction:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> a = np.arange(60.).reshape(3,4,5)\u001b[0m\n",
      "\u001b[0;34m    >>> b = np.arange(24.).reshape(4,3,2)\u001b[0m\n",
      "\u001b[0;34m    >>> np.einsum('ijk,jil->kl', a, b)\u001b[0m\n",
      "\u001b[0;34m    array([[4400., 4730.],\u001b[0m\n",
      "\u001b[0;34m           [4532., 4874.],\u001b[0m\n",
      "\u001b[0;34m           [4664., 5018.],\u001b[0m\n",
      "\u001b[0;34m           [4796., 5162.],\u001b[0m\n",
      "\u001b[0;34m           [4928., 5306.]])\u001b[0m\n",
      "\u001b[0;34m    >>> np.einsum(a, [0,1,2], b, [1,0,3], [2,3])\u001b[0m\n",
      "\u001b[0;34m    array([[4400., 4730.],\u001b[0m\n",
      "\u001b[0;34m           [4532., 4874.],\u001b[0m\n",
      "\u001b[0;34m           [4664., 5018.],\u001b[0m\n",
      "\u001b[0;34m           [4796., 5162.],\u001b[0m\n",
      "\u001b[0;34m           [4928., 5306.]])\u001b[0m\n",
      "\u001b[0;34m    >>> np.tensordot(a,b, axes=([1,0],[0,1]))\u001b[0m\n",
      "\u001b[0;34m    array([[4400., 4730.],\u001b[0m\n",
      "\u001b[0;34m           [4532., 4874.],\u001b[0m\n",
      "\u001b[0;34m           [4664., 5018.],\u001b[0m\n",
      "\u001b[0;34m           [4796., 5162.],\u001b[0m\n",
      "\u001b[0;34m           [4928., 5306.]])\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Writeable returned arrays (since version 1.10.0):\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> a = np.zeros((3, 3))\u001b[0m\n",
      "\u001b[0;34m    >>> np.einsum('ii->i', a)[:] = 1\u001b[0m\n",
      "\u001b[0;34m    >>> a\u001b[0m\n",
      "\u001b[0;34m    array([[1., 0., 0.],\u001b[0m\n",
      "\u001b[0;34m           [0., 1., 0.],\u001b[0m\n",
      "\u001b[0;34m           [0., 0., 1.]])\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Example of ellipsis use:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> a = np.arange(6).reshape((3,2))\u001b[0m\n",
      "\u001b[0;34m    >>> b = np.arange(12).reshape((4,3))\u001b[0m\n",
      "\u001b[0;34m    >>> np.einsum('ki,jk->ij', a, b)\u001b[0m\n",
      "\u001b[0;34m    array([[10, 28, 46, 64],\u001b[0m\n",
      "\u001b[0;34m           [13, 40, 67, 94]])\u001b[0m\n",
      "\u001b[0;34m    >>> np.einsum('ki,...k->i...', a, b)\u001b[0m\n",
      "\u001b[0;34m    array([[10, 28, 46, 64],\u001b[0m\n",
      "\u001b[0;34m           [13, 40, 67, 94]])\u001b[0m\n",
      "\u001b[0;34m    >>> np.einsum('k...,jk', a, b)\u001b[0m\n",
      "\u001b[0;34m    array([[10, 28, 46, 64],\u001b[0m\n",
      "\u001b[0;34m           [13, 40, 67, 94]])\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Chained array operations. For more complicated contractions, speed ups\u001b[0m\n",
      "\u001b[0;34m    might be achieved by repeatedly computing a 'greedy' path or pre-computing the\u001b[0m\n",
      "\u001b[0;34m    'optimal' path and repeatedly applying it, using an\u001b[0m\n",
      "\u001b[0;34m    `einsum_path` insertion (since version 1.12.0). Performance improvements can be\u001b[0m\n",
      "\u001b[0;34m    particularly significant with larger arrays:\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> a = np.ones(64).reshape(2,4,8)\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Basic `einsum`: ~1520ms  (benchmarked on 3.1GHz Intel i5.)\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> for iteration in range(500):\u001b[0m\n",
      "\u001b[0;34m    ...     _ = np.einsum('ijk,ilm,njm,nlk,abc->',a,a,a,a,a)\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Sub-optimal `einsum` (due to repeated path calculation time): ~330ms\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> for iteration in range(500):\u001b[0m\n",
      "\u001b[0;34m    ...     _ = np.einsum('ijk,ilm,njm,nlk,abc->',a,a,a,a,a, optimize='optimal')\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Greedy `einsum` (faster optimal path approximation): ~160ms\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> for iteration in range(500):\u001b[0m\n",
      "\u001b[0;34m    ...     _ = np.einsum('ijk,ilm,njm,nlk,abc->',a,a,a,a,a, optimize='greedy')\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    Optimal `einsum` (best usage pattern in some use cases): ~110ms\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    >>> path = np.einsum_path('ijk,ilm,njm,nlk,abc->',a,a,a,a,a, optimize='optimal')[0]\u001b[0m\n",
      "\u001b[0;34m    >>> for iteration in range(500):\u001b[0m\n",
      "\u001b[0;34m    ...     _ = np.einsum('ijk,ilm,njm,nlk,abc->',a,a,a,a,a, optimize=path)\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m    \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Special handling if out is specified\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mspecified_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# If no optimization, run pure einsum\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0moptimize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mspecified_out\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'out'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mc_einsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moperands\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Check the kwargs to avoid a more cryptic error later, without having to\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# repeat default values here\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mvalid_einsum_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'dtype'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'order'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'casting'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0munknown_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                      \u001b[0mk\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalid_einsum_kwargs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munknown_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Did not understand the following kwargs: %s\"\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                        \u001b[0;34m%\u001b[0m \u001b[0munknown_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Build the contraction list and operand\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0moperands\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meinsum_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moperands\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                                             \u001b[0meinsum_call\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Handle order kwarg for output array, c_einsum allows mixed case\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0moutput_order\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'order'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'K'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0moutput_order\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'A'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_contiguous\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moperands\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0moutput_order\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'F'\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0moutput_order\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'C'\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;31m# Start contraction loop\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mfor\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontraction\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontraction_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0minds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx_rm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meinsum_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontraction\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mtmp_operands\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moperands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# Do we need to deal with the output?\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0mhandle_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecified_out\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontraction_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# Call tensordot if still possible\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mif\u001b[0m \u001b[0mblas\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# Checks have already been handled\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0minput_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meinsum_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'->'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0minput_left\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_right\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_str\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mtensor_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_left\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_right\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0midx_rm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mtensor_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# Find indices to contract over\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mleft_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx_rm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mleft_pos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_left\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mright_pos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_right\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# Contract!\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mnew_view\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensordot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtmp_operands\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# Build a new view if needed\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtensor_result\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mresults_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mhandle_out\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0;32mif\u001b[0m \u001b[0mhandle_out\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                    \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"out\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mnew_view\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_einsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_result\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'->'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mresults_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_view\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# Call einsum\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# If out was specified\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;32mif\u001b[0m \u001b[0mhandle_out\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m                \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"out\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0;31m# Do the contraction\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m            \u001b[0mnew_view\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_einsum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meinsum_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtmp_operands\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;31m# Append new items and dereference what we can\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0moperands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mdel\u001b[0m \u001b[0mtmp_operands\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_view\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32mif\u001b[0m \u001b[0mspecified_out\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m        \u001b[0;32mreturn\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperands\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFile:\u001b[0m      ~/Documents/fastaifromscratch/fastai-from-scratch/fastai/lib/python3.10/site-packages/numpy/core/einsumfunc.py\n",
      "\u001b[0;31mType:\u001b[0m      function\n"
     ]
    }
   ],
   "source": [
    "np.einsum??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a9ff61a4b43343b6cea103718d4de94c0444552ecaf22005224c50b67943e91f"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('fastai': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
